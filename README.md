# ğŸ™ï¸ Smart Meeting Scribe : AI Transcription & Diarization (VRAM Optimized)

Smart Meeting Scribe est une solution d'IA locale ("On-Premise") permettant de transcrire des rÃ©unions audio/vidÃ©o tout en identifiant prÃ©cisÃ©ment qui parle par son nom grÃ¢ce Ã  la reconnaissance biomÃ©trique vocale.

Cette version V4 "Identification" est optimisÃ©e pour Ã©conomiser la mÃ©moire vidÃ©o (VRAM) en utilisant une stratÃ©gie de chargement sÃ©quentiel des modÃ¨les.

## âš™ï¸ Fonctionnement Global (Le Pipeline)

L'application fonctionne par Ã©tapes successives (Pipeline SÃ©quentiel) pour garantir qu'un seul modÃ¨le IA occupe le GPU Ã  un instant T.

```mermaid
graph TD
    A[ğŸ“ Fichier EntrÃ©e .m4a/.mp4] -->|FFmpeg| B(ğŸ”Š Fichier WAV 16kHz)
    
    B --> C{Ã‰tape 1 : Diarisation}
    C -->|"ğŸ“¥ Charge Pyannote"| D[ğŸ•µï¸ Segmentation des locuteurs]
    D -->|"ğŸ§¹ Vide VRAM"| E{Ã‰tape 2 : Identification}
    
    E -->|"ğŸ“¥ Charge WeSpeaker"| F[ğŸ‘¤ Comparaison avec Voice Bank]
    F -->|"ğŸ§¹ Vide VRAM"| G{Ã‰tape 3 : Transcription}
    
    G -->|"ğŸ“¥ Charge Whisper"| H[âœï¸ Conversion Audio â†’ Texte]
    H -->|"ğŸ§¹ Vide VRAM"| I{Ã‰tape 4 : Fusion}
    
    I -->|CPU| J[ğŸ§© Alignement Texte + Noms RÃ©els]
    J --> K[ğŸ’¾ Archivage JSON]
```

| Ã‰tape | ModÃ¨le / Outil | Description |
|-------|----------------|-------------|
| Normalisation | FFmpeg | Conversion en WAV 16kHz Mono (Standard Or pour l'IA). |
| Diarisation | Pyannote 3.1 | SÃ©pare les flux de paroles (SPEAKER_00, SPEAKER_01...). |
| Identification | WeSpeaker | Compare les voix dÃ©tectÃ©es avec les fichiers du dossier `voice_bank/`. |
| Transcription | Whisper Large-v3 | Extrait le texte haute prÃ©cision via Faster-Whisper. |
| Fusion | Algorithme CPU | Attribue les noms rÃ©els aux phrases dans le JSON final. |

## ï¿½ La "Voice Bank" (Reconnaissance Vocale)

Pour que l'IA puisse dire "Julien" au lieu de "SPEAKER_01", vous devez lui fournir des rÃ©fÃ©rences.

1. CrÃ©ez des fichiers audio courts (10-15s) de chaque personne.
2. Placez-les dans `backend-python/voice_bank/`.
3. Nommez les fichiers par le nom de la personne (ex: `Julien.wav`, `Sarah.wav`).

L'IA calculera automatiquement une empreinte mathÃ©matique (Embedding) pour chaque fichier et l'utilisera pour identifier les participants lors de la fusion.

## ğŸ“‚ Structure du Projet

```bash
.
â”œâ”€â”€ docker-compose.yml       
â”œâ”€â”€ .env                     # Token Hugging Face
â””â”€â”€ backend-python/          
    â”œâ”€â”€ main.py              # Point d'entrÃ©e (~25 lignes)
    â”œâ”€â”€ ARCHITECTURE.md      # Documentation technique
    â”œâ”€â”€ api/                 # ğŸ†• Couche Transport (HTTP)
    â”‚   â””â”€â”€ v1/
    â”‚       â”œâ”€â”€ router.py    # Hub central des routes
    â”‚       â””â”€â”€ endpoints/
    â”‚           â”œâ”€â”€ transcribe.py   # POST /api/v1/process/
    â”‚           â””â”€â”€ voice_bank.py   # GET /api/v1/voice-bank/
    â”œâ”€â”€ services/            # Couche MÃ©tier (IA)
    â”‚   â”œâ”€â”€ audio.py         # FFmpeg - Conversion
    â”‚   â”œâ”€â”€ diarization.py   # Pyannote - "Qui parle quand?"
    â”‚   â”œâ”€â”€ identification.py # WeSpeaker - "C'est qui?"
    â”‚   â”œâ”€â”€ transcription.py # Whisper - "Qu'est-ce qui est dit?"
    â”‚   â”œâ”€â”€ fusion.py        # Alignement Texte + Noms
    â”‚   â””â”€â”€ storage.py       # Sauvegarde JSON
    â”œâ”€â”€ core/                # Couche Infrastructure
    â”‚   â”œâ”€â”€ config.py        # ParamÃ¨tres (GPU, tokens)
    â”‚   â””â”€â”€ models.py        # Gestionnaire VRAM (Load/Unload)
    â”œâ”€â”€ voice_bank/          # Voix de rÃ©fÃ©rence (.wav)
    â””â”€â”€ recordings/          # RÃ©sultats archivÃ©s (JSON)
```

## ğŸŒ API Endpoints

| MÃ©thode | Route | Description |
|---------|-------|-------------|
| GET | `/` | Health check + statut GPU |
| POST | `/api/v1/process/` | Transcription audio complÃ¨te |
| GET | `/api/v1/voice-bank/` | Liste des voix enregistrÃ©es |

### Exemple d'utilisation

```bash
# Health check
curl http://localhost:5000/

# Transcription d'un fichier audio
curl -X POST "http://localhost:5000/api/v1/process/" -F "file=@reunion.mp3"

# Lister les voix enregistrÃ©es
curl http://localhost:5000/api/v1/voice-bank/
```

ğŸ“– Documentation Swagger : http://localhost:5000/docs

## ğŸš€ Installation & DÃ©marrage

### 1. Configuration des secrets (.env)

```bash
HF_TOKEN=votre_token_hugging_face_ici
```

### 2. DÃ©marrage

```bash
docker compose up -d --build
```

### 3. VÃ©rification des logs

```bash
docker compose logs -f backend-python
```

Lors de l'analyse, vous devriez voir :

```
ğŸ” [2/4] Identification des locuteurs...
   ğŸ‘¤ Signature vocale enregistrÃ©e pour : Homme
   ï¿½ Signature vocale enregistrÃ©e pour : Femme
      âœ¨ SPEAKER_01 identifiÃ© comme : Homme (Score: 0.99)
```

## ï¿½ï¸ Stack Technique

| Composant | Technologie |
|-----------|-------------|
| Container | Docker + NVIDIA Container Toolkit |
| Base Image | nvidia/cuda:12.4.1-runtime-ubuntu22.04 |
| Backend | Python 3.10 + FastAPI |
| Transcription | Faster-Whisper Large-v3 (INT8/FP16) |
| Diarisation | Pyannote Audio 3.1 |
| Identification | WeSpeaker (ResNet34 VoxCeleb) |
| MathÃ©matiques | NumPy / SciPy (Distance Cosinus) |

## ğŸ“‹ PrÃ©-requis Hugging Face

âœ… Vous devez accepter les conditions d'utilisation pour :

- [Pyannote Segmentation 3.0](https://huggingface.co/pyannote/segmentation-3.0)
- [Pyannote Speaker Diarization 3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
- [WeSpeaker VoxCeleb](https://huggingface.co/pyannote/wespeaker-voxceleb-resnet34-LM)
