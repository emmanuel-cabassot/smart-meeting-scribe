# ğŸ”§ Workers - TaskIQ Background Processing

Service de traitement asynchrone des tÃ¢ches audio/vidÃ©o avec GPU.

## ğŸ—ï¸ Architecture

```
app/
â”œâ”€â”€ broker.py              # Configuration TaskIQ + Redis
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py          # Variables d'environnement
â”‚   â””â”€â”€ models.py          # Chargement/libÃ©ration modÃ¨les IA
â”œâ”€â”€ services/              # Logique mÃ©tier IA
â”‚   â”œâ”€â”€ audio.py           # Conversion audio (FFmpeg)
â”‚   â”œâ”€â”€ diarization.py     # Pyannote (GPU)
â”‚   â”œâ”€â”€ transcription.py   # Whisper (GPU)
â”‚   â”œâ”€â”€ identification.py  # WeSpeaker (GPU) - lit depuis S3
â”‚   â”œâ”€â”€ fusion.py          # Merge diarization + transcription
â”‚   â””â”€â”€ storage.py         # Sauvegarde S3/MinIO
â””â”€â”€ worker/
    â””â”€â”€ tasks/             # ğŸ“ TÃ¢ches TaskIQ modulaires
        â”œâ”€â”€ __init__.py    # Export central
        â”œâ”€â”€ base.py        # Utilitaires S3, cleanup
        â”œâ”€â”€ audio_tasks.py # TÃ¢ches audio (transcription)
        â””â”€â”€ video_tasks.py # TÃ¢ches vidÃ©o (templates)
```

## ğŸ¯ Identity Bank (S3)

Les signatures vocales sont stockÃ©es sur MinIO pour l'identification des locuteurs :

```
ğŸ“ s3://identity-bank/
   â””â”€â”€ {user_id}/                    # "default" pour l'instant
       â””â”€â”€ {person_id}/              # Ex: "emmanuel"
           â”œâ”€â”€ profile.json          # MÃ©tadonnÃ©es
           â”œâ”€â”€ voice/sample.wav      # Ã‰chantillon vocal
           â””â”€â”€ face/                 # (PrÃ©vu pour reconnaissance faciale)
```

**Ajouter une nouvelle voix :**
1. Uploader vers `s3://identity-bank/default/{nom}/voice/sample.wav`
2. CrÃ©er `profile.json` : `{"name": "Nom", "created_at": "..."}`

## ğŸš€ TÃ¢ches disponibles

| TÃ¢che | Description | Fichier |
|-------|-------------|---------|
| `process_transcription_full` | Pipeline : diarisation â†’ identification â†’ transcription â†’ fusion | `audio_tasks.py` |

## â• Ajouter une nouvelle tÃ¢che

### 1. ImplÃ©menter dans le fichier appropriÃ©

```python
# audio_tasks.py ou video_tasks.py
from app.broker import broker
from app.worker.tasks.base import smart_download, cleanup_files

@broker.task(task_name="ma_nouvelle_tache")
async def ma_nouvelle_tache(file_path: str, job_id: str):
    local_file = None
    try:
        local_file = f"/tmp/{job_id}_file.wav"
        smart_download(file_path, local_file)
        # ... traitement
        return {"status": "success", "job_id": job_id}
    finally:
        cleanup_files([local_file], job_id)
```

### 2. Exporter dans `tasks/__init__.py`

```python
from app.worker.tasks.audio_tasks import ma_nouvelle_tache

__all__ = [
    "process_transcription_full",
    "ma_nouvelle_tache",  # â† Ajouter
]
```

### 3. Appeler depuis l'API

```python
from app.worker.tasks import ma_nouvelle_tache

result = await ma_nouvelle_tache.kiq(file_path, job_id)
```

## ğŸ³ Docker

```bash
# Build
docker build -t smart-scribe-worker .

# Run (nÃ©cessite GPU)
docker run --gpus all smart-scribe-worker
```

## âš™ï¸ Variables d'environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `REDIS_URL` | URL du broker Redis | `redis://redis:6379` |
| `MINIO_ENDPOINT` | Endpoint MinIO | `minio:9000` |
| `MINIO_ACCESS_KEY` | ClÃ© d'accÃ¨s MinIO | - |
| `MINIO_SECRET_KEY` | ClÃ© secrÃ¨te MinIO | - |
| `HF_TOKEN` | Token HuggingFace (Pyannote) | - |

## ğŸ“Š Gestion VRAM

Le worker optimise l'usage GPU en chargeant/dÃ©chargeant les modÃ¨les sÃ©quentiellement :

1. **Pyannote** (diarisation) â†’ libÃ©rÃ©
2. **WeSpeaker** (identification) â†’ libÃ©rÃ©  
3. **Whisper** (transcription) â†’ libÃ©rÃ©

Cela permet de faire tourner tous les modÃ¨les sur une GPU avec ~8GB VRAM.

## ğŸ“¦ Buckets S3/MinIO

| Bucket | Usage |
|--------|-------|
| `uploads` | Fichiers audio/vidÃ©o entrants |
| `processed` | RÃ©sultats (JSON transcription, diarisation, fusion) |
| `identity-bank` | Signatures vocales pour identification |
