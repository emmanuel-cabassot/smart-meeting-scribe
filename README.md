# ğŸ™ï¸ Smart Meeting Scribe : GPU-Accelerated Diarization & Transcription

Smart Meeting Scribe est une API locale haute performance capable de transcrire des fichiers audio/vidÃ©o tout en identifiant qui parle et quand (Diarisation).

L'application combine la puissance de Faster-Whisper (Large-v3) pour le texte et de Pyannote Audio 3.1 pour l'analyse des locuteurs, le tout orchestrÃ© par un algorithme de fusion intelligent.

## ğŸ—ï¸ Architecture Technique

Le projet suit une philosophie "Clean Host" : l'intÃ©gralitÃ© de la stack (FFmpeg, Python, CUDA Libraries) tourne dans un conteneur isolÃ©. Votre machine hÃ´te reste propre.

### Le Pipeline Hybride

```mermaid
graph LR
A[Fichier Audio/VidÃ©o] --> B(Conversion FFmpeg 16kHz)
B --> C{Traitement ParallÃ¨le}
C --> D[ğŸ•µï¸ Diarisation Pyannote]
C --> E[âœï¸ Transcription Whisper]
D --> F[ğŸ§© Algorithme de Fusion]
E --> F
F --> G[ğŸ’¾ JSON & Archives]
```

- **HÃ´te requis** : Linux (Ubuntu recommandÃ©) + Drivers NVIDIA.
- **Conteneur** : CUDA 12.4.1 (Image officielle NVIDIA).
- **Backend** : Python 3.10, FastAPI.
- **IA** : PyTorch 2.x, calculs optimisÃ©s (INT8/FLOAT16 + TF32).

## ğŸ“‚ Structure du projet

```bash
.
â”œâ”€â”€ docker-compose.yml       # Orchestration & Gestion GPU
â”œâ”€â”€ .env                     # Tokens secrets (Hugging Face)
â”œâ”€â”€ README.md                # Documentation
â”œâ”€â”€ ARCHITECTURE.md          # DÃ©tails techniques du pipeline
â””â”€â”€ backend-python/          # Microservice IA
    â”œâ”€â”€ Dockerfile           # Environnement (CUDA 12.4, FFmpeg)
    â”œâ”€â”€ requirements.txt     # Librairies (Whisper, Pyannote...)
    â”œâ”€â”€ main.py              # Logique API & Fusion
    â””â”€â”€ recordings/          # ğŸ“‚ Dossier montÃ© : Archives des analyses
```

## ğŸ“‹ PrÃ©-requis (Sur la machine hÃ´te)

- **NVIDIA Drivers** : InstallÃ©s sur l'hÃ´te (`nvidia-smi` doit fonctionner).
- **Docker & Docker Compose** : InstallÃ©s.
- **NVIDIA Container Toolkit** : ConfigurÃ© pour que Docker puisse voir le GPU.
- **Compte Hugging Face** : Indispensable pour tÃ©lÃ©charger le modÃ¨le Pyannote 3.1.
  - Accepter les conditions d'utilisation sur [cette page](https://huggingface.co/pyannote/speaker-diarization-3.1).
  - CrÃ©er un Access Token (Read).

## ğŸš€ Installation & DÃ©marrage

### 1. Cloner le projet

```bash
git clone <votre-repo>
cd smart-meeting-scribe
```

### 2. Configuration du Token

CrÃ©ez un fichier `.env` Ã  la racine pour y mettre votre token Hugging Face :

```bash
# CrÃ©e le fichier .env
echo "HF_TOKEN=votre_token_hugging_face_ici" > .env
```

### 3. Lancer la Stack

Docker va construire l'image, tÃ©lÃ©charger les dÃ©pendances et dÃ©marrer le serveur.

```bash
docker compose up -d --build
```

Le premier lancement peut prendre quelques minutes (tÃ©lÃ©chargement des modÃ¨les IA).

### 4. VÃ©rification

VÃ©rifiez les logs pour confirmer que le GPU, Whisper et Pyannote sont chargÃ©s :

```bash
docker compose logs -f backend-python
```

Vous devez voir : `âœ… Pipeline chargÃ© !` et `ğŸš€ GPU DÃ©tectÃ©.` (Ctrl+C pour quitter les logs)

## ğŸ–¥ï¸ Utilisation

L'API expose une interface Swagger UI pour tester facilement.

1. Ouvrez votre navigateur sur : [http://localhost:5000/docs](http://localhost:5000/docs)
2. Allez sur la route `POST /transcribe`.
3. Chargez un fichier audio ou vidÃ©o (mp3, wav, m4a, mp4...).
4. Cliquez sur **Execute**.

### Format de Sortie (JSON)

L'API retourne (et sauvegarde dans `backend-python/recordings/`) un rÃ©sultat structurÃ© :

```json
{
  "metadata": {
    "filename": "meeting_marketing.m4a",
    "duration": 45.2,
    "saved_at": "recordings/20240104_1530_meeting"
  },
  "segments": [
    {
      "start": 0.0,
      "end": 2.5,
      "text": "Bonjour Ã  tous, commenÃ§ons.",
      "speaker": "SPEAKER_00"
    },
    {
      "start": 2.8,
      "end": 5.1,
      "text": "Merci d'Ãªtre prÃ©sents pour ce point budget.",
      "speaker": "SPEAKER_01"
    }
  ]
}
```

## ï¿½ï¸ DÃ©pannage Courant

- **Erreur Permission Denied sur `recordings/`** : Assurez-vous que votre utilisateur Linux a les droits d'Ã©criture sur le dossier ou lancez Docker avec les bonnes permissions UID/GID.

- **Erreur Pyannote (401/403)** : VÃ©rifiez que votre `HF_TOKEN` est valide dans le `.env` et que vous avez bien acceptÃ© les conditions sur le site Hugging Face.

- **MÃ©moire GPU insuffisante** : Whisper Large-v3 + Pyannote nÃ©cessitent environ 6 Ã  8 Go de VRAM. Si vous avez moins, modifiez `main.py` pour utiliser Whisper `medium` ou `small`.
