# üèóÔ∏è Architecture Technique : Smart Meeting Scribe V2.5

> **Version** : 2.5 (Architecture Asynchrone Optimis√©e)  
> **Approche** : "Clean Host" & "AI Native"  
> **Cible** : D√©ploiement On-Premise (Docker) sur GPU unique (Consumer Grade - ex: RTX 4070)

Ce document sert de r√©f√©rence pour comprendre les choix technologiques, la gestion des flux de donn√©es et la strat√©gie de performance GPU.

---

## 1. Vue d'Ensemble & Philosophie

Le passage de la **V1** (Script Monolithique) √† la **V2.5** vise √† transformer un outil de script en une v√©ritable **plateforme SaaS interne robuste**.

### Les 3 Piliers de l'Architecture

| Pilier | Description |
|--------|-------------|
| **D√©couplage Total** | L'API qui re√ßoit les fichiers n'est jamais celle qui les traite. Cela garantit que l'interface utilisateur reste fluide, m√™me si le serveur calcule depuis 2 heures. |
| **Zero-Copy Storage** | Contrairement aux architectures Cloud complexes (S3/MinIO), nous profitons d'√™tre sur un serveur unique pour utiliser des **Volumes Partag√©s**. L'API √©crit sur le disque, le Worker lit sur le m√™me disque. Latence : **0ms**. |
| **Discipline VRAM Stricte** | Le syst√®me est con√ßu pour ne jamais planter par manque de m√©moire vid√©o. Les t√¢ches sont s√©rialis√©es (une par une) et la m√©moire est purg√©e apr√®s chaque √©tape. |

---

## 2. La Stack Technologique (D√©tail)

### üåê Couche Infrastructure & R√©seau

| Composant | R√¥le |
|-----------|------|
| **Docker Compose** | Orchestrateur unique. Tout le syst√®me d√©marre avec une seule commande. L'h√¥te n'a besoin que de Docker et des Drivers NVIDIA. |
| **Traefik** (Reverse Proxy) | Porte d'entr√©e unique (Port 80). Route le trafic : `/api` ‚Üí Backend, `/` ‚Üí Frontend (futur Next.js). G√®re le Load Balancing et la s√©curit√© SSL (futur). |

### ‚ö° Couche Application (Backend)

| Composant | R√¥le | Performance |
|-----------|------|-------------|
| **FastAPI** (Python) | *Guichetier*. Re√ßoit le fichier, v√©rifie l'auth, le pose sur le disque, et cr√©e un ticket dans Redis. | Temps de r√©ponse < 200ms |
| **ARQ** (Job Queue) | Rempla√ßant moderne de Celery. Con√ßu pour `asyncio` (standard Python moderne). Plus l√©ger, d√©marre plus vite, g√®re mieux les processus GPU sans "zombies". | ‚Äî |

> [!TIP]
> **Pourquoi ARQ plut√¥t que Celery ?**  
> Celery est vieux et lourd. ARQ est natif `asyncio`, s'int√®gre parfaitement avec FastAPI, et ne laisse pas de processus orphelins lors des longues t√¢ches GPU.

### üß† Couche Intelligence (Worker IA)

Le "Cerveau" du syst√®me. **Isol√© dans son propre conteneur Docker.**

| Mod√®le | Fonction | Notes |
|--------|----------|-------|
| **Faster-Whisper** (Large-v3) | Transcription audio ‚Üí texte | Version optimis√©e (CTranslate2), **4x plus rapide** que le Whisper original d'OpenAI |
| **Pyannote Audio 3.1** | Diarisation ("Qui parle quand ?") | Module le plus gourmand, ex√©cut√© en priorit√© |
| **WeSpeaker** (VoxCeleb) | Identification biom√©trique | Compare la voix aux embeddings de `voice_bank/` |

### üíæ Couche Donn√©es (Persistence)

| Composant | R√¥le |
|-----------|------|
| **Redis 7** (Alpine) | **Broker** : File d'attente des t√¢ches. **Cache** : √âtat des jobs ("En cours", "Fini"). |
| **PostgreSQL 15** (Alpine) | M√©moire √† long terme. Stocke utilisateurs, historique des r√©unions, m√©tadonn√©es (dur√©e, locuteurs), liens vers fichiers. |
| **Docker Shared Volumes** | Stockage physique des fichiers `.mp3`, `.wav` et r√©sultats `.json`. Remplace MinIO. Acc√®s disque direct (NVMe), pas de r√©seau. |

---

## 3. Flux de Donn√©es (Workflow)

Voici le trajet exact d'une r√©union, de l'upload √† la lecture.

```mermaid
sequenceDiagram
    participant User as üë§ Utilisateur
    participant API as ‚ö° FastAPI
    participant Redis as üî¥ Redis
    participant Worker as üß† Worker ARQ
    participant Volume as üíæ Volume Partag√©
    participant DB as üêò PostgreSQL

    User->>API: POST reunion.mp3
    API->>Volume: Sauvegarde /data/uploads/
    API->>Redis: Enqueue job "process_audio"
    API-->>User: 202 Accepted - ID: 123
    
    Note over Redis: Job en attente...
    
    Worker->>Redis: Poll job
    Redis-->>Worker: Job #123
    Worker->>Volume: Lecture reunion.mp3
    
    Note over Worker: Phase 1: Conversion WAV (CPU)
    Note over Worker: Phase 2: Diarisation (GPU) ‚Üí Flush VRAM
    Note over Worker: Phase 3: Identification (GPU) ‚Üí Flush VRAM
    Note over Worker: Phase 4: Transcription (GPU) ‚Üí Flush VRAM
    Note over Worker: Phase 5: Fusion (CPU)
    
    Worker->>Volume: √âcrit result.json
    Worker->>DB: UPDATE job #123 = "Termin√©"
    Worker->>Redis: Job complete
```

### √âtapes D√©taill√©es

1. **Ingestion (API)**
   - L'utilisateur envoie `reunion.mp3`
   - FastAPI sauvegarde dans `/data/uploads/` (Volume partag√©)
   - FastAPI envoie l'ordre `process_audio` √† Redis
   - FastAPI r√©pond `"OK, ID = 123"` √† l'utilisateur

2. **Mise en File (Redis)**
   - Le job attend dans la RAM de Redis
   - Si 10 jobs arrivent, ils s'alignent (FIFO)

3. **Traitement (Worker ARQ)**
   - Le Worker (qui surveille Redis) voit le job
   - Il lit directement le fichier dans `/data/uploads/`
   - **Phase 1** : Conversion WAV (CPU)
   - **Phase 2** : Diarisation (GPU - Pyannote) ‚Üí `Flush VRAM`
   - **Phase 3** : Identification (GPU - WeSpeaker) ‚Üí `Flush VRAM`
   - **Phase 4** : Transcription (GPU - Whisper) ‚Üí `Flush VRAM`
   - **Phase 5** : Fusion des donn√©es (CPU)

4. **Stockage & Restitution**
   - Le Worker √©crit le JSON final dans `/data/results/`
   - Le Worker notifie PostgreSQL que le job #123 est "Termin√©"

---

## 4. Strat√©gie de Gestion GPU (VRAM)

> [!CAUTION]
> C'est le point critique pour la stabilit√© du syst√®me.

### R√®gles Fondamentales

| R√®gle | Impl√©mentation |
|-------|----------------|
| **Concurrency = 1** | Le Worker traite strictement **une seule t√¢che** √† la fois |
| **Load / Unload** | Les mod√®les ne restent pas charg√©s en m√©moire |
| **Protection Async** | Pendant le calcul GPU, le CPU envoie des heartbeats √† Redis |

### Cycle de Vie des Mod√®les

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  1. Charger Whisper en VRAM                                 ‚îÇ
‚îÇ  2. Ex√©cuter l'inf√©rence (transcription)                    ‚îÇ
‚îÇ  3. Supprimer l'objet Python (del model)                    ‚îÇ
‚îÇ  4. Appeler gc.collect()                                    ‚îÇ
‚îÇ  5. Vider le cache CUDA (torch.cuda.empty_cache())          ‚îÇ
‚îÇ  6. ‚Üí VRAM libre pour le mod√®le suivant                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

> [!NOTE]
> Cette strat√©gie permet de faire tourner des mod√®les √©normes (Large-v3 : ~6GB) sur des cartes modestes (8GB VRAM) sans erreur OOM.

---

## 5. √âvolutions Futures (Architecture Pr√™te)

Cette architecture V2.5 est con√ßue pour accueillir les briques suivantes **sans tout casser** :

### üîÆ Roadmap

| Feature | Composant | Statut |
|---------|-----------|--------|
| **RAG** (Retrieval Augmented Generation) | Qdrant + BGE-M3 | üü° Pr√©vu |
| **Anonymisation GDPR** | GLiNER (NER l√©ger) | üü° Pr√©vu |
| **Frontend Web** | Next.js | üü° Pr√©vu |

### RAG (Retrieval Augmented Generation)

- Le conteneur **Qdrant** est d√©j√† pr√©vu dans le r√©seau Docker
- Le Worker pourra g√©n√©rer des vecteurs (via **BGE-M3**) et les pousser dans Qdrant apr√®s la transcription
- Permettra de "questionner" les r√©unions pass√©es

### Anonymisation (GDPR)

- Int√©gration pr√©vue de **GLiNER** (CPU/GPU l√©ger)
- S'ex√©cutera juste apr√®s la transcription
- Remplacera les noms propres avant stockage d√©finitif

### Frontend Next.js

- Il suffira d'ajouter le conteneur `frontend` dans `docker-compose.yml`
- Traefik fera le lien automatiquement vers `/`

---

## üìä Diagramme d'Architecture Globale

```mermaid
graph TB
    subgraph Internet
        User["üë§ Utilisateur"]
    end
    
    subgraph Docker Network
        Traefik["üîÄ Traefik :80"]
        
        subgraph Backend
            API["‚ö° FastAPI"]
            Worker["üß† Worker ARQ"]
        end
        
        subgraph Data Layer
            Redis[("üî¥ Redis")]
            Postgres[("üêò PostgreSQL")]
            Volumes["üíæ Volumes"]
        end
        
        subgraph Future
            Qdrant[("üîÆ Qdrant")]
            Frontend["üåê Next.js"]
        end
    end
    
    User --> Traefik
    Traefik --> API
    Traefik -.-> Frontend
    
    API --> Redis
    API --> Volumes
    Worker --> Redis
    Worker --> Volumes
    Worker --> Postgres
    Worker -.-> Qdrant
    
    style Future fill:#f9f,stroke:#333,stroke-dasharray: 5 5
```

---

*Document mis √† jour le 10 janvier 2026*
